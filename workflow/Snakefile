'''Workflow for the CAMP MAG QC module.'''


from contextlib import redirect_stderr
import glob
from os import makedirs, remove
from os.path import basename, exists, getsize, isdir, join
import pandas as pd
from utils import Workflow_Dirs, ingest_samples, add_bin_num, get_bin_nums, pair_mag_refs, parse_dnadiff, aggregate_quast # polymut_from_cmseq


# Load and/or make the working directory structure
dirs = Workflow_Dirs(config['work_dir'], 'mag_qc')


# Load sample names and input files 
SAMPLES = ingest_samples(config['samples'], dirs.TMP)


# Specify the location of any external resources and scripts
dirs_ext = config['ext'] # join(dirname(abspath(__file__)), 'ext')
dirs_scr = join(dirs_ext, 'scripts')


# --- Workflow output --- #


rule all:
    input:
        join(dirs.OUT, 'final_reports', 'complete.txt') 


# --- Workflow steps --- #


rule checkm2:
    input:
        join(dirs.TMP, '{sample}.out'),
    output:
        join(dirs.OUT, '0_checkm2', '{sample}', 'quality_report.tsv'),
        # n50_sz = join(dirs.OUT, '0_checkm2', '{sample}', 'storage/bin_stats_ext.tsv'),
    log:
        join(dirs.LOG, 'checkm', '{sample}.checkm2.out'), 
    conda:
        join(config['env_yamls'], 'checkm2.yaml'),
    threads: config['checkm_threads'],
    resources:
        mem_mb = config['checkm_mem_mb'],
    params:
        extension ='fa',
        bin_dir = join(dirs.TMP, '{sample}'),
        out_dir = join(dirs.OUT, '0_checkm2', '{sample}'),
        checkm2_db = config['checkm2_db'],
        # tmp_0 = join(dirs.OUT, '0_checkm2', '{sample}', 'quality_report.tsv'),
        # tmp_1 = join(dirs.OUT, '0_checkm2', '{sample}', 'tmp_1.csv'),
        # tmp_2 = join(dirs.OUT, '0_checkm2', '{sample}', 'tmp_2.csv'),
    shell:
        """
        checkm2 predict --threads {threads} --input {params.bin_dir} --output-directory {params.out_dir} \
            -x {params.extension} --database_path {params.checkm2_db} --force > {log} 2>&1
        """


rule checkm_sh:
    input:
        join(dirs.TMP, '{sample}.out'),
    output:
        join(dirs.OUT, '1_checkm1', 'strain_het', '{sample}', 'report.tsv'),
    log:
        join(dirs.LOG, 'checkm', '{sample}.strain_het.out'), 
    threads: config['checkm_threads'],
    resources:
        mem_mb = config['checkm_mem_mb'],
    params:
        ext ='fa',
        bin_dir = join(dirs.TMP, '{sample}'),
        out_dir = join(dirs.OUT, '1_checkm1', 'strain_het', '{sample}'),
        checkm1_db = config['checkm1_db'],
    shell:
        """
        checkm data setRoot {params.checkm1_db}
        checkm lineage_wf -t {threads} -x {params.ext} --tab_table \
            -f {output} {params.bin_dir} {params.out_dir} > {log} 2>&1
        """


rule index_mag_bam:
    input:
        join(dirs.TMP, '{sample}.bam'),
    output:
        join(dirs.TMP, '{sample}.bam.bai'),
    threads: config['checkm_threads'],
    resources: 
        mem_mb = config['checkm_mem_mb'],
    shell:
        """
        samtools index -@ {threads} {input}
        """


rule checkm_cov:
    input:
        join(dirs.TMP, '{sample}.out'),
        join(dirs.TMP, '{sample}.bam.bai'),
    output:
        join(dirs.OUT, '1_checkm1', 'mag_ra', '{sample}', 'report_raw.tsv'),
    log:
        join(dirs.LOG, 'checkm', '{sample}.mag_ra.out'), 
    threads: config['checkm_threads'],
    resources:
        mem_mb = config['checkm_mem_mb'],
    params:
        ext ='fa',
        bin_dir = join(dirs.TMP, '{sample}'),
        out_dir = join(dirs.OUT, '1_checkm1', 'mag_ra', '{sample}'),
        bam = join(dirs.TMP, '{sample}.bam'),
    shell:
        """
        rm -r {params.out_dir}
        checkm coverage -t {threads} -x {params.ext} {params.bin_dir} \
            {output} {params.bam} > {log} 2>&1
        """


rule aggregate_cov:
    input:
        join(dirs.OUT, '1_checkm1', 'mag_ra', '{sample}', 'report_raw.tsv'),
    output:
        join(dirs.OUT, '1_checkm1', 'mag_ra', '{sample}', 'report.csv'),
    params:
        calc_script = join(dirs_scr, 'calc_mag_ra.py'),
    shell:
        """
        python {params.calc_script} {input} {output}
        """


rule gunc:
    input:
        join(dirs.TMP, '{sample}.out'),
    output:
        join(dirs.OUT, '2_gunc', '{sample}', 'GUNC.progenomes_2.1.maxCSS_level.tsv'),
    log:
        join(dirs.LOG, 'gunc', '{sample}.out'),
    threads: config['gunc_threads'],
    resources:
        mem_mb = config['gunc_mem_mb'],
    params:
        bin_dir = join(dirs.TMP, '{sample}'),
        out_dir = join(dirs.OUT, '2_gunc', '{sample}'),
        diamond_db = config['diamond_db'],
    shell:
        """
        mkdir -p {params.out_dir}
        gunc run --input_dir {params.bin_dir} --out_dir {params.out_dir} --db_file {params.diamond_db} --threads {threads} > {log} 2>&1
        """


rule gtdbtk:
    input:
        join(dirs.TMP, '{sample}.out'),
    output:
        join(dirs.OUT, '3_gtdbtk', '{sample}', 'report.tsv'),
    log:
        join(dirs.LOG, 'gtdbtk', '{sample}.out'),
    threads: config['gtdbtk_threads'],
    resources:
        mem_mb = config['gtdbtk_mem_mb'],
    params:
        bin_dir = join(dirs.TMP, '{sample}'),
        out_dir = join(dirs.OUT, '3_gtdbtk', '{sample}'),
        gtdb_db = config['gtdb_db'],
        ext = 'fa',
    shell:
        """
        export GTDBTK_DATA_PATH={params.gtdb_db} 
        gtdbtk classify_wf --genome_dir {params.bin_dir} --out_dir {params.out_dir} -x {params.ext} \
            --cpus {threads} --pplacer_cpus 1 --force > {log} 2>&1 || echo 'No MAGs were classified' > {log} 2>&1
            # --force makes it complete even without proteins
        if [[ -f "{params.out_dir}/gtdbtk.bac120.summary.tsv" ]]; then
            cp {params.out_dir}/gtdbtk.bac120.summary.tsv {output}
        else
            touch {output}
        fi
        """


rule get_mag_refs:
    input:
        join(dirs.OUT, '3_gtdbtk', '{sample}', 'report.tsv'),
    output:
        join(dirs.OUT, '4_dnadiff', '{sample}', 'mag_refs.out'),
    params:
        out_dir = join(dirs.OUT, '4_dnadiff', '{sample}'),
        gtdb_db = config['gtdb_db'],
    run:
        if not isdir(params.out_dir): makedirs(params.out_dir)
        if getsize(str(input)) != 0:
            df = pd.read_csv(str(input), sep = '\t')
            df.apply(lambda row : pair_mag_refs(row, params.out_dir, params.gtdb_db), axis = 1)
        open(str(output), 'w').close()


rule dnadiff:
    input:
        fa = join(dirs.TMP, '{sample}', '{bin_num}.fa'),
        made_ref = join(dirs.OUT, '4_dnadiff', '{sample}', 'mag_refs.out'),
    output:
        ref = join(dirs.OUT, '4_dnadiff', '{sample}', '{bin_num}.ref.fa'),
        rep = join(dirs.OUT, '4_dnadiff', '{sample}', '{bin_num}' + '.report'),
    log:
        join(dirs.LOG, 'dnadiff', '{sample}.{bin_num}.out'), 
    params:
        prefix = join(dirs.OUT, '4_dnadiff', '{sample}', '{bin_num}'),
        ref = join(dirs.OUT, '4_dnadiff', '{sample}', '{bin_num}.ref'),
    shell:
        """
        if [[ -f "{params.ref}" ]]; then
            REF_PATH=`cat {params.ref}`
            if [[ -f "$REF_PATH" ]]; then
                zcat $REF_PATH > {output.ref}
                dnadiff {output.ref} {input.fa} -p {params.prefix} > {log}
            else
                touch {output.ref}
                touch {output.rep}
            fi
        else
            touch {output.ref}
            touch {output.rep}
        fi
        """


rule parse_dnadiff:
    input:
        join(dirs.OUT, '4_dnadiff', '{sample}', '{bin_num}' + '.report'),
    output:
        join(dirs.OUT, '4_dnadiff', '{sample}', '{bin_num}' + '.diff.tsv'),
    run:
        parse_dnadiff(str(input), str(output))


rule aggregate_dnadiff:
    input:
        lambda wildcards: expand(rules.parse_dnadiff.output, bin_num = get_bin_nums(wildcards.sample, dirs.TMP), sample = wildcards.sample),
    output:
        join(dirs.OUT, '4_dnadiff', '{sample}', 'report.tsv'),
    shell:
        """
        tmp=`echo -n "{input}" | wc -c`
        if [ $tmp -gt 0 ]; # Only if there are (refined) bins generated
        then
            cat {input}>{output}
        else
            touch {output}
        fi
        """


rule quast:
    input:
        fa = join(dirs.TMP,'{sample}','{bin_num}.fa'),
        ref = join(dirs.OUT,'4_dnadiff','{sample}','{bin_num}.ref.fa'),
    output:
        join(dirs.OUT, '5_quast', '{sample}', '{bin_num}', 'report.tsv'),
    log:
        join(dirs.LOG, 'quast', '{sample}.{bin_num}.out'), 
    conda:
        join(config['env_yamls'], 'quast.yaml'),
    threads: config['quast_threads'],
    resources:
        mem_mb = config['quast_mem_mb'],
    params:
        out_dir = join(dirs.OUT, '5_quast', '{sample}', '{bin_num}'),
        min_len = config['min_contig_len'],
    shell:
        """
        quast.py --threads {threads} -r {input.ref} -m {params.min_len} -o {params.out_dir} {input.fa} --no-plots || touch {output} > {log} 2>&1
        """


rule aggregate_quast:
    input:
        lambda wildcards: expand(rules.quast.output, bin_num = get_bin_nums(wildcards.sample, dirs.TMP), sample = wildcards.sample),
    output:
        join(dirs.OUT, '5_quast', '{sample}', 'report.csv'),
    run:
        aggregate_quast(input, str(output))



rule ctg_name_edit:
    input:
        join(dirs.TMP, '{sample}', '{bin_num}.fa'),
    output:
        join(dirs.OUT, '6_prokka', '{sample}', 'bins', '{bin_num}.fa'),
    params:
        out_dir = join(dirs.OUT, '6_prokka', '{sample}', 'bins'),
        tmp = join(dirs.TMP, '{sample}', '{bin_num}.tmp.fa'),
        out = join(dirs.TMP, '{sample}', '{bin_num}.fa'),
    shell:
        """
        mkdir -p {params.out_dir}
        if awk '/^>/ {{ if(length($0) > 38) exit 1 }}' {input}; then
            mv {input} {params.tmp}
            awk '/^>/ {{ if(length($0) > 38) print substr($0, 1, 38); \
            else print }} !/^>/ {{ print }}' {params.tmp} > {output}
        else
            ln -s {input} {output}
        fi
        """


rule prokka:
    input:
        join(dirs.OUT, '6_prokka', '{sample}', 'bins', '{bin_num}.fa'),
    output:
        join(dirs.OUT, '6_prokka', '{sample}', 'bin.{bin_num}.txt'),
        join(dirs.OUT, '6_prokka', '{sample}', 'bin.{bin_num}.tsv'),
    log:
        join(dirs.LOG, 'prokka', '{sample}.{bin_num}.out'), 
    conda:
        join(config['env_yamls'], 'prokka.yaml'),
    threads: config['prokka_threads'],
    params:
        out_dir = join(dirs.OUT, '6_prokka', '{sample}'),
        in_fa = join(dirs.TMP, '{sample}', '{bin_num}.fa'),
        prefix = 'bin.{bin_num}',
    shell:
        """
        prokka {params.in_fa} --kingdom Bacteria --outdir {params.out_dir} \
            --prefix {params.prefix} --locustag {params.prefix} \
            --force --cpus {threads} > {log} 2>&1
        """


rule summarize_gene_cts:
    input:
        txt = join(dirs.OUT, '6_prokka', '{sample}', 'bin.{bin_num}.txt'),
        tsv = join(dirs.OUT, '6_prokka', '{sample}', 'bin.{bin_num}.tsv'),
    output:
        join(dirs.OUT, '6_prokka', '{sample}', 'bin.{bin_num}.csv'),
    params:
        summ_script = join(dirs_scr, 'summarize_gene_cts.py'),
        prefix = 'bin.{bin_num}',
    shell:
        """
        python {params.summ_script} {input.txt} {input.tsv} {params.prefix} {output}
        """ 


rule aggregate_gene_cts:
    input:
        lambda wildcards: expand(rules.summarize_gene_cts.output, bin_num = get_bin_nums(wildcards.sample, dirs.TMP), sample = wildcards.sample),
    output:
        join(dirs.OUT, '6_prokka', '{sample}', 'report.csv'),
    shell:
        """
        cat {input} > {output}
        """ 


rule summarize_reports:
    input:
        checkm2 = join(dirs.OUT, '0_checkm2', '{sample}', 'quality_report.tsv'),
        strain_het = join(dirs.OUT, '1_checkm1', 'strain_het', '{sample}', 'report.tsv'),
        mag_ra = join(dirs.OUT, '1_checkm1', 'mag_ra', '{sample}', 'report.csv'),
        gunc = join(dirs.OUT, '2_gunc', '{sample}', 'GUNC.progenomes_2.1.maxCSS_level.tsv'),
        gtdb = join(dirs.OUT, '3_gtdbtk', '{sample}', 'report.tsv'),
        diff = join(dirs.OUT, '4_dnadiff', '{sample}', 'report.tsv'),
        quast = join(dirs.OUT, '5_quast', '{sample}', 'report.csv'),
        gene_cts = join(dirs.OUT, '6_prokka', '{sample}', 'report.csv'),
    output:
        join(dirs.OUT, 'final_reports', '{sample}.summary.csv'),
    params:
        summ_script = join(dirs_scr, 'summarize_reports.py'),
    shell:
        """
        python {params.summ_script} {input.checkm2} {input.strain_het} {input.mag_ra} {input.gunc} {input.gtdb} {input.diff} {input.quast} {input.gene_cts} {output} 
        """



rule make_config:
    input:
        expand(join(dirs.OUT, 'final_reports', '{sample}.summary.csv'), sample = SAMPLES),
    output:
        join(dirs.OUT, 'final_reports', 'complete.txt'),
    params:
        out_dir = join(dirs.OUT, 'final_reports'),
    run:
        open(str(output), 'w').close()

